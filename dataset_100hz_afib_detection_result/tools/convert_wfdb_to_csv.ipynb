{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_wf_files(subject_dir, subject_id, output_dir):\n",
    "    \"\"\"\n",
    "    Aggregate data from WF files corresponding to a subject ID into separate CSV files for each WF file name,\n",
    "    and combine all PPG values into a single file named after the .hea file.\n",
    "\n",
    "    Args:\n",
    "        subject_dir (str): Path to the directory containing all files for the subject ID.\n",
    "        subject_id (str): Subject ID.\n",
    "        output_dir (str): Output directory to save the CSV files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Iterate through all files in the subject directory\n",
    "        for file_name in os.listdir(subject_dir):\n",
    "            # Check if the file is a .hea file and starts with the subject_id\n",
    "            if file_name.endswith('.hea') and file_name.startswith(subject_id) and not file_name[-5] == 'n':\n",
    "                # Full path of the .hea file\n",
    "                hea_path = os.path.join(subject_dir, file_name)\n",
    "\n",
    "                # Read the content of the .hea file\n",
    "                with open(hea_path, 'r') as hea_file:\n",
    "                    lines = hea_file.readlines()\n",
    "\n",
    "                # Get the list of available files in the directory (without extensions)\n",
    "                available_files = {os.path.splitext(f)[0] for f in os.listdir(subject_dir)}\n",
    "\n",
    "                # Prepare a list to store combined PPG data for this .hea file\n",
    "                combined_ppg_data = []\n",
    "\n",
    "                # Process each line in the .hea file\n",
    "                for line in lines:\n",
    "                    # Find all valid file names in the line\n",
    "                    matches = re.findall(r'\\b\\d{7}_\\d{4}\\b', line)\n",
    "                    for match in matches:\n",
    "                        if match in available_files:\n",
    "                            wf_path = os.path.join(subject_dir, match)\n",
    "                            try:\n",
    "                                # Read the corresponding .dat file\n",
    "                                record = wfdb.rdrecord(wf_path)\n",
    "\n",
    "                                # Extract PPG signal from the first channel\n",
    "                                ppg_data = record.p_signal[:, 0]\n",
    "\n",
    "                                # Append PPG data to the combined list\n",
    "                                combined_ppg_data.extend(ppg_data)\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing {match}: {e}\")\n",
    "\n",
    "                # Save the combined PPG data into a single CSV file named after the .hea file\n",
    "                combined_file_name = os.path.splitext(file_name)[0] + \".csv\"\n",
    "                combined_csv_file = os.path.join(output_dir, combined_file_name)\n",
    "                combined_df = pd.DataFrame(combined_ppg_data)\n",
    "                combined_df.to_csv(combined_csv_file, index = False, header = False)\n",
    "                print(f\"All PPG data from {file_name[:-4]} has been combined and saved to {combined_csv_file}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subject directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List of subject IDs\n",
    "subject_ids = ['p000608', 'p000776', 'p000946', 'p004490', 'p004829',\n",
    "               'p009526', 'p010391', 'p013072', 'p013136', 'p014079',\n",
    "               'p015852', 'p016684', 'p017344', 'p019608', 'p022954',\n",
    "               'p023824', 'p025117', 'p026377', 'p026964', 'p029512',\n",
    "               'p043613', 'p050089', 'p050384', 'p055204', 'p058932',\n",
    "               'p062160', 'p063039', 'p063628', 'p068956', 'p069339',\n",
    "               'p075371', 'p075796', 'p077729', 'p079998', 'p081349',\n",
    "               'p085866', 'p087275', 'p087675', 'p089565', 'p089964',\n",
    "               'p092289', 'p092846', 'p094847', 'p097547', 'p099674',]\n",
    "\n",
    "base_subject_dir = 'I:/mimic_dataset/wfdb_dataset_125hz'\n",
    "base_output_dir = 'I:/mimic_dataset/csv_dataset_125hz'\n",
    "\n",
    "for subject_id in subject_ids:\n",
    "    subject_directory = os.path.join(base_subject_dir, subject_id)\n",
    "    output_directory = os.path.join(base_output_dir, subject_id)\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok = True)\n",
    "\n",
    "    aggregate_wf_files(subject_directory, subject_id, output_directory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
